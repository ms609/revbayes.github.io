<!doctype html>
<html lang="en">
<link rel="icon" type="image/png" href="/assets/img/favicon.png" >
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="search-domain" value="https://revbayes.github.io/">
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />
    <title>RevBayes: Continuous trait evolution and Brownian motion</title>
  </head>
  <body>
    <div class="container">
      <nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
      <a href="/" class="pull-left">
        
        <img class="navbar-logo" src="/assets/img/aquabayes-desaturated.png" alt="RevBayes Home" />
        
      </a>
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar" align="right"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="/download">Download</a></li>
        <li><a href="/tutorials/">Tutorials</a></li>
        <li><a href="/documentation/">Documentation</a></li>
        <li><a href="https://revbayes.github.io/revscripter/">RevScripter</a></li>
        <li><a href="/workshops/">Workshops</a></li>
        <li><a href="/jobs/">Jobs</a></li>
        <li><a href="/developer/">Developer</a></li>
      </ul>
      <!-- <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form> -->
    </div>
  </div>
</nav>

      <div class="titlebar">
	<h1 class="maintitle">Continuous trait evolution and Brownian motion</h1>
	<h3 class="subtitle">Phylogenetic analysis of continous characters and the comparative method</h3>
	<h4 class="authors">Nicolas Lartillot and Sebastian Höhna</h4>
  <h5>Last modified on September 12, 2019</h5>
</div>


<div class="sidebar no-print">
<blockquote class="overview" id="overview">
  <h2>Overview</h2>
  
  <div class="row">
    <div class="col-md-9">
        <strong>Prerequisites</strong>
        
          <ul id="prerequisites">
          
            <li><a href="/tutorials/intro/">Getting Started with RevBayes and Rev Language Syntax</a></li>
          
          </ul>
        
    </div>
  </div>
  
</blockquote>





</div>
<h1 id="introduction">Introduction</h1>

<p>The subject of the comparative method is the analysis of trait evolution
at the macroevolutionary scale. In a comparative context, many different
questions can be addressed: tempo and mode of evolution, correlated
evolution of multiple quantitative traits, trends and bursts, changes in
evolutionary mode correlated with major key innovations in some groups,
etc [for a good introduction see @Harvey1991].</p>

<p>In order to correctly formalize comparative questions, the underlying
phylogeny should always be explicitly accounted for. This point is
clearly illustrated, in particular, by the independent contrasts method
(missing reference). Practically speaking, the
phylogeny and the divergence times are usually first estimated using a
separate phylogenetic reconstruction software. In a second step, this
time-calibrated phylogeny is used as an input to the comparative method.
Doing this, however, raises a certain number of methodological problems:</p>

<ul>
  <li>
    <p>the uncertainty about the phylogeny (and about divergence times) is
ignored</p>
  </li>
  <li>
    <p>the traits themselves may have something to say about the phylogeny</p>
  </li>
  <li>
    <p>the rate of substitution, and more generally the parameters of the
substitution process, can also be seen as quantitative traits,
amenable to a comparative analysis.</p>
  </li>
</ul>

<p>All these points are not easily formalized in the context of the
step-wise approach mentioned above. Instead, what all this suggests is
that phylogenetic reconstruction, molecular dating and the comparative
method should all be considered jointly, in the context of one single
overarching probabilistic model.</p>

<p>Thanks to its modular structure, RevBayes represents a natural
framework for attempting this integration. The aim of the present
tutorial is to guide you through a series of examples where this
integration is achieved, step by step. It can also be considered as an
example of the more general perspective of <em>integrative modeling</em>, which
can be recruited in many other contexts.</p>

<h1 id="data-and-files">Data and files</h1>

<p>We provide several data files which we will use in this tutorial. You
may want to use your own data instead. In the <code class="language-plaintext highlighter-rouge">data</code> folder, you will
find the following files</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">primates_cytb.nex</code>: Alignment of the <em>cytochrome b</em> subunit from
23 primates representing 14 of the 16 families (<em>Indriidae</em> and
<em>Callitrichidae</em> are missing).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">primates_lhtlog.nex</code>: 2 life-history traits (endocranial volume
(ECV), body mass; each for males and females separately) for 23
primate species [taken from the Anage database, @DeMagalhaes2009].
The traits have been log-transformed.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">primates.tree</code>: A time calibrated phylogeny of the same
23 primates.</p>
  </li>
</ul>

<h1 id="univariate">Univariate Brownian evolution of quantitative traits</h1>

<p>As a first preliminary exercise, we wish to reconstruct the evolution of
body mass in primates and, in particular, estimate the body mass of
their last common ancestor. For this, we will assume that the logarithm
of body mass follows a simple univariate Brownian motion along the
phylogeny. In a first step, we will ignore phylogenetic uncertainty:
thus, we will assume that the Brownian process describing body mass
evolution runs along a fixed time-calibrated phylogeny (with fixed
divergence times), such as specified in the file <code class="language-plaintext highlighter-rouge">primates.tree</code>.</p>

<p><br />
You may want to take the time to visualize the tree given in
<code class="language-plaintext highlighter-rouge">primates.tree</code> as well as the matrix of quantitative traits specified
by the <code class="language-plaintext highlighter-rouge">primates_lhtlog.nex</code> file, before going into the modeling work
described below.</p>

<h2 id="the-model-and-the-priors">The model and the priors</h2>

<p>A univariate Brownian motion $x(t)$ is parameterized by its starting
value at the root of the phylogeny $x(0)$ and a rate parameter $\sigma$.
This rate parameter tunes the amplitude of the variation per unit of
time. Specifically, along a given time interval $(0,T)$, the value of
$X$ at time $T$ is normally distributed, with mean $x(0)$ and variance
$\sigma^2 T$: \(\begin{aligned}
x(T) &amp; \sim &amp; \text{Normal} \left( x(0), \sigma^2 T \right).\end{aligned}\)</p>

<p>Concerning $\sigma$, we can formalize the idea that we are ignorant
about the <em>scale</em> (the order of magnitude) of this parameter by using a
log-uniform prior: \(\begin{aligned}
\sigma &amp;\sim&amp; \frac{1}{\sigma}.\end{aligned}\)</p>

<p>Concerning the initial value $x(0)$ of the Brownian process at the root
of the phylogeny. Alternatively, you may want to specify a normal
distribution as the prior distribution on the root value if you have
some prior information.</p>

<p>Finally, the tree topology $\psi$ is, as mentioned above, fixed to some
externally given phylogeny. The entire model is now specified: tree
$\psi$, variance $\sigma$ and Brownian process $x(t)$: \(\begin{aligned}
\sigma &amp;\sim&amp; \frac{1}{\sigma},
\\
x(0) &amp;\sim&amp; \text{Uniform},
\\
x(t) \mid \Psi, \sigma &amp;\sim&amp; \text{Brownian} \left( x(0), \, \psi, \, \sigma \right).\end{aligned}\)
Conditioning the model on empirical data by clamping $x(t)$ at the tips
of the phylogeny, we can then run a MCMC to sample from the joint
posterior distribution on $\sigma$ and $x$. Once this is done, we can
obtain posterior means, medians or credible intervals for the value of
body mass or other life-history traits for specific ancestors.</p>

<h2 id="programming-the-model-in-revbayes">Programming the model in RevBayes</h2>

<p>The problem of continuous trait evolution —just as for discrete trait
evolution— along a phylogeny is that we do not know the values of the
traits at the internal nodes. That means, that we need to treat the
states at the internal nodes as additional parameters of the model. For
discrete characters we use the sum-product (a.k.a. pruning) algorithm
<a class="citation" href="#Felsenstein1981">(Felsenstein 1981)</a> to analytically integrate over all possible states at
the internal nodes. For continuous characters (traits) similar methods
have been proposed. In RevBayes you have three main ways of specifying
this model and running an analysis on it. The three approaches are: (1)
phylogenetic independent contrasts using the reduced likelihood (REML),
(2) Brownian motion using a phylogenetic covariance matrix, and (3) a
full Brownian motion model using data augmentation. Each of these
approaches has there advantages and disadvantages as will be explained
below. Nevertheless, all approaches give the same results in terms of
rate estimation.</p>

<h2 id="phylogenetic-independent-contrasts-using-the-reduced-likelihood-reml">Phylogenetic Independent Contrasts using the reduced likelihood (REML)</h2>

<p>The reduced or restricted maximum likelihood (REML) method computes the
probability of observing the continuous character at the tips by an
analytical solution to integrate over the internal states
<a class="citation" href="#Felsenstein1985">(Felsenstein 1985)</a>. This analytical solution is very fast to compute and
thus can be applied to large phylogenies and/or many independent
characters. However, the REML method looses the information about the
location of the root state and thus you cannot infer which state the
root or other internal nodes have.</p>

<p>You do not need to understand the algorithm but we provide a sketch of
the idea behind REML to give you some insights. REML compute the values
at the internal nodes as the phylogenetic contrasts $x_k = x_i - x_j$
where $x_i$ and $x_j$ are the values of the child nodes in the
phylogeny. Then, we can compute the probability of observing the
contrast $x_k$ using the probability density of a normal distribution
with mean $\mu = 0$ and standard deviation
$\sigma = \sqrt{\nu_i + \delta_i + \nu_j + \delta_j}$ where $\nu_i$ and
$\nu_j$ are the (scaled) branch lengths leading to node $i$ and $j$
respectively. $\delta$ is the additional uncertainty that is propagated
through the phylogeny and is compute by
$\delta_k = ((\nu_i + \delta_i)*(\nu_j + \delta_j)) / (\nu_i + \delta_i + \nu_j + \delta_j)$.
These computations are done for you in the RevBayes distribution
called <code class="language-plaintext highlighter-rouge">dnPhyloBrownianREML</code>.</p>

<p>In the directory <code class="language-plaintext highlighter-rouge">RevBayes_scripts/</code> you will find a script called
<code class="language-plaintext highlighter-rouge">primatesMass_BM_REML.Rev</code>. This script implements the univariate
Brownian model described above. Instead of re-typing the content of
script entirely in the context of an interactive RevBayes session, you
can instead run the script directly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>source("RevBayes_scripts/primatesMass_BM_REML.Rev")
</code></pre></div></div>

<p>This script essentially reformulates what has been explained in the last
subsection and serves as an example solution for you. For the later
section you need to adjust the script.</p>

<p>Let us go through the script step by step in the <code class="language-plaintext highlighter-rouge">Rev</code> language. First,
load the trait data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>contData &lt;- readContinuousCharacterData("data/primates_lhtlog.nex")
</code></pre></div></div>

<p>If you type you will see that the continuous character data matrix
contains several characters (columns).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>contData
</code></pre></div></div>

<div class="language-plaintext rev-output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    
       Continuous character matrix with 23 taxa and 11 characters
       ==========================================================
       Origination:                   primates_lhtlog.nex
       Number of taxa:                23
       Number of included taxa:       23
       Number of characters:          11
       Number of included characters: 11
       Datatype:                      Continuous
</code></pre></div></div>

<p>Since we only want the body mass (of females) we exclude all but the
third character</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>contData.excludeAll()
contData.includeCharacter(3) 
</code></pre></div></div>

<p>Next, load the time-tree from file. Remember that we use in this first
simple example a fixed tree that we assume is known without uncertainty.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>treeArray &lt;- readTrees("data/primates.tree")
psi &lt;- treeArray[1]
</code></pre></div></div>

<p><br />
You may want to look at this tree before by loading the <code class="language-plaintext highlighter-rouge">primates.tree</code>
in FigTree or any other tree visualization software.</p>

<p>As usual, we start be initializing some useful helper variables. For
example, we set up a counter variable for the number of moves that we
already added to our analysis. This will make it much easier if we
extend the model or analysis to include additional moves or to remove
some moves.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mvi = 0 
</code></pre></div></div>

<p>Then, we define the overall rate parameter $\sigma$ which we assign a
(truncated) log-uniform prior. Note that it is more efficient in
Bayesian inference to specify a uniform prior and then to transform the
parameter which we will use here:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logSigma ~ dnUniform(-5,5)
sigma := 10^logSigma
</code></pre></div></div>

<p>Using this approach we have specified a prior probability distribution
on <code class="language-plaintext highlighter-rouge">sigma</code> between $10^{-5}$ to $10^5$ which should be broad enough to
include all reasonable values. Since the rate of trait evolution
<code class="language-plaintext highlighter-rouge">logSigma</code> is a stochastic variable and we want to estimate it, we need
to add a sliding move on it. Remember that the sliding move proposes new
values drawn from a window with width <code class="language-plaintext highlighter-rouge">delta</code> and is centered around the
current values; thus it slides through the parameter space together with
the current parameter value.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSlide(logSigma, delta=1.0, tune=true, weight=2.0)
</code></pre></div></div>

<p>Next, define a random variable from the univariate Brownian-Phylo-REML
process, which we will call <code class="language-plaintext highlighter-rouge">logmass</code>. We need to provide the tree
variable <code class="language-plaintext highlighter-rouge">psi</code>, some branch-specific rate multiplier parameter which we
simply set to 1, the shared rate for this site <code class="language-plaintext highlighter-rouge">sigma</code> and the number of
sites (number of continuous traits) that we use.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logmass ~ dnPhyloBrownianREML(psi, branchRates=1.0, siteRates=sigma, nSites=1)
</code></pre></div></div>

<p>Now, condition the Brownian model on empirically observed values for
body mass in the extant taxa.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logmass.clamp( contData )
</code></pre></div></div>

<p>The model is now entirely specified and we can create a model object
containing the entire model graph by providing it with only one of our
model variables, <em>e.g.</em>, <code class="language-plaintext highlighter-rouge">sigma</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mymodel = model(sigma)
</code></pre></div></div>

<p>To see what it happing during the MCMC let us make a screen monitor that
tracks the rate <code class="language-plaintext highlighter-rouge">sigma</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[1] = mnScreen(printgen=10, sigma)
</code></pre></div></div>

<p>Additionally, we’ll use a file monitor that does the same thing, but
directly stores the values into a file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[2] = mnFile(filename="output/primates_mass_REML.log", printgen=10, separator = TAB, sigma)
</code></pre></div></div>

<p>We can finally create a mcmc, and run it for a good 100 000 cycles after
we did a burnin phase of 10 000 iterations:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mymcmc = mcmc(mymodel, monitors, moves)
mymcmc.burnin(generations=10000,tuningInterval=500)
mymcmc.run(100000)
</code></pre></div></div>

<h2 id="exercises-exercises-unnumbered">Exercises {#exercises .unnumbered}</h2>

<ul>
  <li>
    <p>Run the model.</p>
  </li>
  <li>
    <p>using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the rate
parameter <code class="language-plaintext highlighter-rouge">sigma</code></p>
  </li>
  <li>
    <p>calculate the 95% credible interval for the rate of evolution of the
log of body mass ($\sigma$)</p>
  </li>
</ul>

<h2 id="phylogenetic-covariance-matrix">Phylogenetic covariance matrix</h2>

<p>The second method that we will use creates a phylogenetic covariance
matrix. The phylogenetic covariance matrix method integrates over the
states at the internal nodes as well but uses instead a multivariate
normal distribution. The key advantage is that this method provides
information about the root state since it models the root state as an
additional parameter of the model. The disadvantage is that it is very
computationally intensive. That means, that the phylogenetic covariance
matrix approach may take long for very large data sets (at least in its
current implementation).</p>

<p><br />
Copy the file <code class="language-plaintext highlighter-rouge">primatesMass_BM_REML.Rev</code>, name it for example
<code class="language-plaintext highlighter-rouge">primatesMass_BM_Cov.Rev</code> and start editing it.</p>

<p>In the previous example, the REML approach, we did not specify a
parameter for the state at the root. In this exercise, we need this
additional parameter. Let us use a uniform prior distribution on the
logarithm of the root mass. A uniform prior between -100 and 100 should
be diffuse enough. Just image how big or small an individual needs to be
if it has body mass smaller than exp(-100) or larger than exp(100).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rootlogmass ~ dnUniform(-100,100)
</code></pre></div></div>

<p>Next, we’ll specify a sliding move that proposes new values for the
<code class="language-plaintext highlighter-rouge">rootlogmass</code> randomly drawn from a window centered around the current
value.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSlide(rootlogmass,delta=10,tune=true,weight=2) 
</code></pre></div></div>

<p>Finally, we need to substitute the <code class="language-plaintext highlighter-rouge">dnPhyloBrownianREML</code> by
<code class="language-plaintext highlighter-rouge">dnPhyloBrownianMVN</code> to use the phylogenetic covariance matrix approach.
Again, we provide the tree variable <code class="language-plaintext highlighter-rouge">psi</code>, some branch-specific rate
multiplier parameter which we simply set to 1, the shared rate for this
site <code class="language-plaintext highlighter-rouge">sigma</code> and the number of sites (number of continuous traits) that
we use.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logmass ~ dnPhyloBrownianMVN(psi, branchRates=1.0, siteRates=sigma, rootStates=rootlogmass, nSites=1)
</code></pre></div></div>

<p>This will automatically connect the parameters of the model together.</p>

<p>Additionally, we now have the extra parameter <code class="language-plaintext highlighter-rouge">rootlogmass</code> which we
want to monitor. Thus we need to replace the file monitor and use
instead.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[2] = mnFile(filename="output/primates_mass_Cov.log", printgen=10, separator = TAB, sigma, rootlogmass)
</code></pre></div></div>

<p><br />
Don’t forget to change the output file names in the monitors, otherwise
your old analyses files will be overwritten.</p>

<h2 id="exercises-exercises-1-unnumbered">Exercises {#exercises-1 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the rate
parameter <code class="language-plaintext highlighter-rouge">sigma</code> and the <code class="language-plaintext highlighter-rouge">rootlogmass</code></p>
  </li>
  <li>
    <p>How does the posterior distribution of <code class="language-plaintext highlighter-rouge">sigma</code> looks compared with
the first analysis?</p>
  </li>
  <li>
    <p>Calculate the 95% credible interval for the rate of evolution of the
log of body mass ($\sigma$) and the <code class="language-plaintext highlighter-rouge">rootlogmass</code></p>
  </li>
</ul>

<h2 id="data-augmentation">Data augmentation</h2>

<p>The third method to we will use is a data augmentation method. The data
augmentation method uses explicitly the states at the internal nodes. We
will specify the full model in <code class="language-plaintext highlighter-rouge">Rev</code>. That means that we will create a
random variable for each node of the tree using a for loop. Each trait
is then simply assign a normal distribution, as we described above in
the model description. The advantage of this method is that you estimate
the values at the internal nodes directly and that you have full control
about modifying any part of the model. The disadvantage is that the MCMC
algorithm will be harder if you want to jointly estimate the phylogeny,
although the likelihood computation is very fast. The problem is the
mixing of the MCMC because proposing new trees involves proposing new
good values for the states at the internal nodes.</p>

<p><br />
Copy the file <code class="language-plaintext highlighter-rouge">primatesMass_BM_REML.Rev</code>, name it for example
<code class="language-plaintext highlighter-rouge">primatesMass_BM_DA.Rev</code> and start editing it.</p>

<p>]As in the previous example we will use a uniform prior distribution on
the logarithm of the root mass.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rootlogmass ~ dnUniform(-100,100)
</code></pre></div></div>

<p>Again, we’ll specify a sliding move that proposes new values for the
<code class="language-plaintext highlighter-rouge">rootlogmass</code> randomly drawn from a window centered around the current
value.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSlide(rootlogmass,delta=10,tune=true,weight=2) 
</code></pre></div></div>

<p>In order to create the random variables for the internal states we need
to know the number of nodes and the number of tips. We will store these
as some helper variables.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numNodes = psi.nnodes()
numTips = psi.ntips()
</code></pre></div></div>

<p>Now we are ready to specify the Brownian motion model for each branch.
That is, we simply specify a new normal distributed random variable for
each node with mean being equal to the value of the parent variable and
the standard deviation being equal to the product of the square root of
the branch length and our rate parameter <code class="language-plaintext highlighter-rouge">sigma</code>. We store all the
variables in the vector <code class="language-plaintext highlighter-rouge">logmass</code>. Then we are able to access the value
at the parent node using the index of the parent node, which we can
obtain from the tree using the function <code class="language-plaintext highlighter-rouge">psi.parent(i)</code>. Similarly,
since the variance depends on the branch length we retrieve the branch
length of node with index <code class="language-plaintext highlighter-rouge">i</code> using the function <code class="language-plaintext highlighter-rouge">psi.branchLength(i)</code>.</p>

<p>First we need to copy (create a reference to) the <code class="language-plaintext highlighter-rouge">rootlogmass</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logmass[numNodes] := rootlogmass
</code></pre></div></div>

<p>Let us start by creating the random variables for the internal nodes.
Remember that the variance is equal to <code class="language-plaintext highlighter-rouge">sigma</code>-squared times the branch
length, and we need to compute the square root of it to obtain the
standard deviation.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># univariate Brownian process along the tree
# parameterized by sigma
for (i in (numNodes-1):(numTips+1) ) {
  logmass[i] ~ dnNormal( logmass[psi.parent(i)], sd=sigma*sqrt(psi.branchLength(i)) )
  # moves on the Brownian process
  moves[++mvi] = mvSlide( logmass[i], delta=10, tune=true ,weight=2) 
}
</code></pre></div></div>

<p>You may have noticed that we specified in the loop a move for each
internal <code class="language-plaintext highlighter-rouge">logmass</code>. This is because we want to use the MCMC algorithm to
integrate over the uncertainty in the states.</p>

<p>Next, we repeat the same loop but now for the tip nodes. Instead of
applying a move to each tip node we will clamp the nodes. The nodes will
be clamped with the data that we read in before.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for (i in numTips:1 ) {
  logmass[i] ~ dnNormal( logmass[psi.parent(i)], sd=sigma*sqrt(psi.branchLength(i)) )

  # condition Brownian model on quantitative trait data (second column of the dataset)
  logmass[i].clamp(contData.getTaxon(psi.nodeName(i))[1])
}
</code></pre></div></div>

<p>Here we do not need a <code class="language-plaintext highlighter-rouge">dnPhyloBrownianREML</code> or <code class="language-plaintext highlighter-rouge">dnPhyloBrownianMVN</code>
distribution anymore because we explicitly instantiated the model. Note
that the approach we have taken using the loop is the tree-plate
approach described in (missing reference)</p>

<p>Since we have several additional parameters —the states at the internal
nodes— we will use a model monitor to write to file instead.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[2] = mnModel(filename="output/primates_mass_DA.log", printgen=10, separator = TAB)
monitors[3] = mnExtNewick(filename="output/primates_mass_DA_ext.trees", isNodeParameter=TRUE, printgen=10, separator = TAB, tree=psi, logmass)
</code></pre></div></div>

<p>To get the annotate tree we use the map tree function.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>treetrace = readTreeTrace("output/primates_mass_DA_ext.trees", treetype="clock")
map_tree = mapTree(treetrace,"output/primates_mass_DA_ext_MAP.tree")
</code></pre></div></div>

<p><br />
Don’t forget to change the output file names in the monitors, otherwise
your old analyses files will be overwritten.</p>

<h2 id="exercises-exercises-2-unnumbered">Exercises {#exercises-2 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the rate
parameter <code class="language-plaintext highlighter-rouge">sigma</code> and the <code class="language-plaintext highlighter-rouge">rootlogmass</code> and the internal states.</p>
  </li>
  <li>
    <p>How does the posterior distribution of <code class="language-plaintext highlighter-rouge">sigma</code> looks compared with
the first and second analysis?</p>
  </li>
  <li>
    <p>Calculate the 95% credible interval for the rate of evolution of the
log of body mass ($\sigma$) and the <code class="language-plaintext highlighter-rouge">rootlogmass</code>. Have they
changed?</p>
  </li>
</ul>

<h2 id="brief-intermediate-summary">Brief intermediate summary</h2>

<p>In the above exercises you have analyzed the log-transformed body mass
using a Brownian motion (BM) along a phylogeny. We assumed the phylogeny
to be known without error and were primarily interested in the rate how
fast the body mass evolves. The exercises showed you three different
ways how to approach the BM model, each having its advantages and
disadvantages. You will need to decide for your analysis which approach
is most appropriate. Our intention was mainly to show you some of the
flexibility in RevBayes how to specify the same model in many
different ways, exposing sometimes more and sometimes less of the
internal model graph structure. As an extra exercise you could start
thinking about how to extend the basic BM.</p>

<h1 id="multiple-independently-evolving-traits">Multiple independently evolving traits</h1>

<p>The Brownian motion can easily be applied to multiple traits. The
exactly same procedure and model will be applied as above and thus we
will skip the repetitive description. The interesting questions that you
can ask about multiple traits is–amongst others–if rates between
traits vary.</p>

<p>As an example we use now the first four characters of the data matrix,
which are: 1) female log endocranial volume (ECV), 2) male log ECV, 3)
female log body mass and 4) male log body mass.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>contData &lt;- readContinuousCharacterData("data/primates_lhtlog.nex")
contData.excludeCharacter(5:11)
</code></pre></div></div>

<p>In the first simple example we assume that all site rates are equal,
thus we use a rate multiplier we we call <code class="language-plaintext highlighter-rouge">perSiteRates</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perSiteRates &lt;- [1,1,1,1]
</code></pre></div></div>

<p>Furthermore, we have now four characters and hence we will estimate a
root state for each one of them. We use the same prior probability for
every character, just as above for the single character example.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for (i in 1:4) {
   rootlogmass[i] ~ dnUniform(-100,100)
   moves[++mvi] = mvSlide(rootlogmass[i],delta=10,tune=true,weight=2) 
}
</code></pre></div></div>

<p>Finally, we bring together all the parameter to specify our Brownian
motion model along the tree. Note that we specify here the site rates as
the product of the global rate <code class="language-plaintext highlighter-rouge">sigma</code> time the sites specific rates
(which are, however all equal in this first exercie).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logmass ~ dnPhyloBrownianMVN(psi, branchRates=1.0, siteRates=sigma*perSiteRates, rootStates=rootlogmass, nSites=4)
</code></pre></div></div>

<p>After this you need to create the model using the <code class="language-plaintext highlighter-rouge">model</code> function,
create your monitors, create the MCMC and finaly run the MCMC.</p>

<h2 id="exercises-exercises-3-unnumbered">Exercises {#exercises-3 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the rate
parameter <code class="language-plaintext highlighter-rouge">sigma</code> and the four <code class="language-plaintext highlighter-rouge">rootlogmass</code> values.</p>
  </li>
  <li>
    <p>Compare the results to the previous single trait analyses?</p>
  </li>
</ul>

<h2 id="independent-site-rates">Independent site rates</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perSiteRates ~ dnDirichlet([1,1,1,1])
moves[++mvi] = mvSimplexElementScale(perSiteRates,alpha=10,tune=true,weight=4)
</code></pre></div></div>

<h2 id="exercises-exercises-4-unnumbered">Exercises {#exercises-4 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the per site
rate parameter <code class="language-plaintext highlighter-rouge">perSiteRates</code>.</p>
  </li>
  <li>
    <p>How are the estimate per site rates compared to each other?</p>
  </li>
</ul>

<h2 id="partially-shared-site-rates">Partially shared site rates</h2>

<p>We hope that your results in the previous analysis showed that the rates
for females and males for both the ECV and the body mass are very
similar. This motivates us to specify an explicit model where the rates
between ECV and body mass evolution are different but shared between
females and males. We will model the difference using the <code class="language-plaintext highlighter-rouge">siteRateDiff</code>
parameter which is drawn from a Beta(1,1) distribution, which is
essentially a uniform distribution between 0 and 1. We still choose the
Beta distribution because it is easier to specify more informative
priors.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>siteRateDiff ~ dnBeta(1,1)
</code></pre></div></div>

<p>Next, we specify a sliding move on the <code class="language-plaintext highlighter-rouge">siteRateDiff</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSlide(siteRateDiff,delta=10,tune=true,weight=2)
</code></pre></div></div>

<p>To obtain the rates we use <code class="language-plaintext highlighter-rouge">siteRateDiff</code> as the rate for the ECV
evolution in females and males and 1-<code class="language-plaintext highlighter-rouge">siteRateDiff</code> as the rate for the
body mass evolution in females and males. Note, however, that we need a
small workaround here. <code class="language-plaintext highlighter-rouge">Rev</code> is a strictly typed language, which you may
have noticed. The per site rates need to be positive real number
(negative rates obviously don’t make sense). However, the difference
between two number is not guaranteed to be positive, only if we know
that the first term is larger than the second. This is exactly the case
for 1-<code class="language-plaintext highlighter-rouge">siteRateDiff</code> but RevBayes doesn’t know this so we need to tell
it by using the absolute value <code class="language-plaintext highlighter-rouge">abs</code> function.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perSiteRates[1] := siteRateDiff
perSiteRates[2] := siteRateDiff
perSiteRates[3] := abs(1.0 - siteRateDiff)   # specify the type here
perSiteRates[4] := abs(1.0 - siteRateDiff)
</code></pre></div></div>

<p>You could have specified many other prior distribution on the relative
rate (or ratio) such as a uniform prior distribution and then use logit
or hyperbolic tangent transformation. The only important factor is that
the rates are somehow normalized because we use the global, shared rate
<code class="language-plaintext highlighter-rouge">sigma</code>. Using the beta distribution makes the rates automatically
normalized because the two different rates sum to one. Note that in the
previous all four rates summed to 1.0 and here the two different rates
sum to 1.0. This has the effect that we should estimate the global rate
<code class="language-plaintext highlighter-rouge">sigma</code> to be half of what you estimated previously. You may want to
check this once you ran the analysis and loaded the output into
<code class="language-plaintext highlighter-rouge">Tracer</code>.</p>

<p>The remaining functions are the same as in the previous example.</p>

<h2 id="exercises-exercises-5-unnumbered">Exercises {#exercises-5 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the per site
rate parameter <code class="language-plaintext highlighter-rouge">perSiteRates</code>.</p>
  </li>
  <li>
    <p>Does the value of equal rate (<code class="language-plaintext highlighter-rouge">siteRateDiff</code>=0.5) fall into the 95%
credible interval?</p>
  </li>
  <li>
    <p>If the rate does not fall into the 95% credible interval, should we
reject the hypothesis that the underlying rates are equal?</p>
  </li>
</ul>

<h2 id="model-selection">Model selection</h2>

<p>Our previous analysis explored the parameters of the rate of evolution.
You will have seen that the rate of evolution was smaller for the ECV
compared with the rate of evolution of body size. However, we did not
perform a statistical test to reject the hypothesis if the underlying
rates between the different characters are significantly different.
Therefore, we will perform a marginal likelihood estimation for all
three model: 1) the equal rates, 2) the independent rates, and 3) the
shared rates.</p>

<p><br />
You need to adopt the three scripts of your previous analysis.</p>

<p>Previously you created an <code class="language-plaintext highlighter-rouge">mymcmc</code> object using the <code class="language-plaintext highlighter-rouge">mcmc</code> function.
Now, you need to replace this object with the power posterior MCMC
object.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pow_p = powerPosterior(mymodel, moves, monitors, "output/pow_p_BM_equal.out", cats=100, sampleFreq=10) 
</code></pre></div></div>

<p>Next, you need to run the burnin and afterwards run the power posterior
sampler. This will create 101 output files (100 stepping stones and one
for the posterior) logging the values into the monitors that you have
specified before (we recommend you not to use a screen monitor). You
could look into each of these files to check that you obtain
sufficiently many samples for each stone.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pow_p.burnin(generations=10000,tuningInterval=250)
pow_p.run(generations=10000)  
</code></pre></div></div>

<p>Use stepping-stone sampling to calculate marginal likelihoods.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ss = steppingStoneSampler(file="output/pow_p_MultiBM_equal.out", powerColumnName="power", likelihoodColumnName="likelihood")
ss.marginal() 
</code></pre></div></div>

<p>RevBayes will print to the screen the estimated marginal likelihood.
Write down this value and repeat the exercise for the other two models.</p>

<h2 id="exercises-exercises-6-unnumbered">Exercises {#exercises-6 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the three different marginal likelihood estimations and write
down the marginal likelihood.</p>
  </li>
  <li>
    <p>Compute the log-Bayes factors by taking the difference of the
alternative model (independent rates &amp; shared rates) and the null
hypothesis (equal rates).</p>
  </li>
  <li>
    <p>Is any of the log-Bayes factors larger than 1.16 for substantial
support of the alternative hypothesis (or 2.3 for strong support)?</p>
  </li>
</ul>

<h1 id="estimating-the-phylogeny-from-continuous-character-data">Estimating the phylogeny from continuous character data</h1>

<p>In the motivation we argued that the phylogeny should be estimated
together with the parameters of the evolutionary process. Only for
simplicity we used fixed trees in the previous exercises. Instead of
using a tree fixed to a pre-defined value, the tree should now be moved
during the MCMC. Implementing this joint model in RevBayes is just a
matter of adding the following features to the model defined in the
previous section (after duplicating the script). You may want to use the
REML approach for computational efficient
(<em>i.e.</em>, good MCMC mixing) although the
phylogenetic covariance matrix and the data augmentation are generally
possible too.</p>

<p>We need to get some useful variables from the data so that we will be
able to specify the tree prior below. These variables are the number of
tips, the number of nodes and the names of the species which we all can
query from the continuous character data object.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>numTips = contData.ntaxa()
names = contData.names()
numNodes = numTips * 2 - 1
</code></pre></div></div>

<p>Instead of having a fixed tree as in the previous, we should now define
a <em>random</em> tree. We use a birth death prior with prior distributions on
the <code class="language-plaintext highlighter-rouge">diversification</code> rate and <code class="language-plaintext highlighter-rouge">turnover</code> rate. The <code class="language-plaintext highlighter-rouge">diversification</code>
rate corresponds to the rate of growth of the tree and the <code class="language-plaintext highlighter-rouge">turnover</code>
rate corresponds to the rate how quickly a species is replaced by a new
one. This parametrization has the advantage that we can use meaningful
prior distributions from the fossil record.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>diversification ~ dnLognormal(0,1)
turnover ~ dnGamma(4,4)
</code></pre></div></div>

<p>Then, we compute deterministically the <code class="language-plaintext highlighter-rouge">speciation</code> and <code class="language-plaintext highlighter-rouge">extinction</code>
rate from the <code class="language-plaintext highlighter-rouge">diversification</code> rate and <code class="language-plaintext highlighter-rouge">turnover</code> rate.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>speciation := diversification + turnover
extinction := turnover
</code></pre></div></div>

<p>Instead, you could also use directly the speciation and extinction
rates, <em>e.g.</em>, endowed with some diffuse
exponential prior.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># rescaling moves on speciation and extinction rates
moves[++mvi] = mvScale(diversification, lambda=1, tune=true, weight=3.0)
moves[++mvi] = mvScale(turnover, lambda=1, tune=true, weight=3.0)
</code></pre></div></div>

<p>The phylogeny that we used are obviously not a complete sample of all
the species and you should take the incomplete sampling into account. We
will simply use an empirical estimate of the fraction of species which
we included in this study. For more information about incomplete taxon
sampling see (missing reference) and (missing reference).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sampling_fraction &lt;- 23 / 270     # 23 out of the ~ 270 primate species
</code></pre></div></div>

<p>Now we are able to specify of tree variable <code class="language-plaintext highlighter-rouge">psi</code> which is drawn from a
constant rate birth-death process. We will condition the age of the tree
to be 75 million years old which is approximately the crown age of
primates, although this estimate is still debated. We only condition
here on the crown age for simplicity because we do not use any other
fossil calibration.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>psi ~ dnBDP(lambda=speciation, mu=extinction, rho=sampling_fraction, rootAge=75, nTaxa=numTips, names=names)
</code></pre></div></div>

<p>Note that, here, we do not have included any fossil information: we are
merely doing <em>relative</em> dating.</p>

<p>The first moves on the tree which we specify are moves that change the
node ages. The first move randomly picks a subtree and rescales it, and
the second move randomly pick a node and uniformly proposes a new node
age between its parent age and oldest child’s age.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSubtreeScale(psi, weight=5.0)
moves[++mvi] = mvNodeTimeSlideUniform(psi, weight=10.0)
</code></pre></div></div>

<p>We also need moves on the tree topology to estimate the phylogeny. The
two moves which you use are the nearest-neighbor interchange (NNI) and
the fixed-nodeheight-prune-and-regraft (FNPR) (missing reference).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvNNI(psi, weight=5.0)
moves[++mvi] = mvFNPR(psi, weight=5.0)
</code></pre></div></div>

<p>We are essentially done now. We only need to add a new monitor for the
tree so that we can monitor and build the maximum a posteriori tree
later.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[3] = mnFile(filename="output/primates_mass_multiBM_tree.trees", printgen=100, separator = TAB, psi)
</code></pre></div></div>

<p><br />
A short analysis of 50 000 iterations will be sufficient.</p>

<h2 id="exercises-exercises-7-unnumbered">Exercises {#exercises-7 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Create the maximum a posteriori (MAP) tree <code class="language-plaintext highlighter-rouge">readTreeTrace</code>
and <code class="language-plaintext highlighter-rouge">mapTree</code>.</p>
  </li>
  <li>
    <p>Look at the estimated tree and compare it to the tree you
used before.</p>
  </li>
  <li>
    <p>How does the posterior distribution of <code class="language-plaintext highlighter-rouge">sigma</code> looks compared with
the first and second analysis?</p>
  </li>
  <li>
    <p>Compute the posterior probabilities of each tree using the
<code class="language-plaintext highlighter-rouge">treetrace.summarize()</code> command.</p>
  </li>
  <li>
    <p>What is the posterior probability of the best tree?</p>
  </li>
</ul>

<h1 id="including-information-about-the-tree-from-molecular-data">Including information about the tree from molecular data</h1>

<p>Starting from the model implemented in the last section, we now want to
account for phylogenetic uncertainty using information contained in
molecular data. As first pointed out by <a class="citation" href="#Huelsenbeck2003">(Huelsenbeck and Rannala 2003)</a>, this can
easily be done in a Bayesian framework, through the use of a joint model
combining sequence data and quantitative traits. Specifically:</p>

<ul>
  <li>
    <p>two data sets are loaded: one for sequence data and one for
quantitative traits</p>
  </li>
  <li>
    <p>a tree is defined under birth-death process</p>
  </li>
  <li>
    <p>a Brownian model is defined over the tree (just as described in the
previous section)</p>
  </li>
  <li>
    <p>the Brownian model is conditioned on the quantitative trait data</p>
  </li>
  <li>
    <p>a substitution model is defined over the same tree (GTR+Gamma)</p>
  </li>
  <li>
    <p>the substitution model is conditioned on the molecular
sequence data.</p>
  </li>
</ul>

<h2 id="programming-the-model-in-revbayes-1">Programming the model in RevBayes</h2>

<p>First, we create a substitution model, just like what you probably did
in previous tutorial
(<em>e.g.</em>, RB_CTMC_Tutorial). In a first step,
we will use a GTR+Gamma model. Start by loading the sequence data matrix
specified in <code class="language-plaintext highlighter-rouge">data/primates_cytb.nex</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seqData &lt;- readDiscreteCharacterData("data/primates_cytb.nex")
</code></pre></div></div>

<p>We can use a flat Dirichlet prior density on the exchangeability rates
<code class="language-plaintext highlighter-rouge">er</code> and the the base frequencies <code class="language-plaintext highlighter-rouge">pi</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>er_prior &lt;- v(1,1,1,1,1,1) 
er ~ dnDirichlet(er_prior)
pi_prior &lt;- v(1,1,1,1) 
pi ~ dnDirichlet(pi_prior)
</code></pre></div></div>

<p>Now add the simplex scale move one each the exchangeability rates <code class="language-plaintext highlighter-rouge">er</code>
and the stationary frequencies <code class="language-plaintext highlighter-rouge">pi</code> to the moves vector:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSimplexElementScale(er) 
moves[++mvi] = mvSimplexElementScale(pi)  
</code></pre></div></div>

<p>We can finish setting up this part of the model by creating a
deterministic node for the GTR instantaneous-rate matrix <code class="language-plaintext highlighter-rouge">Q</code>. The
<code class="language-plaintext highlighter-rouge">fnGTR()</code> function takes a set of exchangeability rates and a set of
base frequencies to compute the instantaneous-rate matrix used when
calculating the likelihood of our model.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Q := fnGTR(er,pi)
</code></pre></div></div>

<p>The next part of the substitution process is the rate variation among
sites. We will model this using the commonly applied 4 discrete gamma
categories which only have a single parameter <code class="language-plaintext highlighter-rouge">alpha</code>. Let us specify
the rate of <code class="language-plaintext highlighter-rouge">alpha</code> to 0.05 (thus the mean will be 20.0).</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>alpha_prior &lt;- 0.05                                                                             
</code></pre></div></div>

<p>Then create a stochastic node called <code class="language-plaintext highlighter-rouge">alpha</code> with an exponential prior:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>alpha ~ dnExponential(alpha_prior)
</code></pre></div></div>

<p>Initialize the <code class="language-plaintext highlighter-rouge">gamma_rates</code> deterministic node vector using the
<code class="language-plaintext highlighter-rouge">fnDiscretizeGamma()</code> function with <code class="language-plaintext highlighter-rouge">4</code> bins:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gamma_rates := fnDiscretizeGamma( alpha, alpha, 4 )
</code></pre></div></div>

<p>The random variable that controls the rate variation is the stochastic
node <code class="language-plaintext highlighter-rouge">alpha</code>. We will apply a simple scale move to this parameter.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvScale(alpha, weight=2.0)
</code></pre></div></div>

<p>This finishes the substitution process part of the model.</p>

<p>Then next part of the model is the clock model. Here we need a clock
model because we work on a time tree. We use our exponentiated uniform
distribution to specify a flat prior distribution which is scale
invariant.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logClockRate ~ dnUniform(-5,5)
clockRate := 10^logClockRate
</code></pre></div></div>

<p>We will apply a sliding window move to the <code class="language-plaintext highlighter-rouge">logClockRate</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[++mvi] = mvSlide(logClockRate, delta=0.1, tune=true, weight=2.0)
</code></pre></div></div>

<p>Remember that you need to call the <code class="language-plaintext highlighter-rouge">PhyloCTMC</code> constructor to include
the new site-rate parameter:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seq ~ dnPhyloCTMC(tree=psi, Q=Q, siteRates=gamma_rates, branchRates=clockRate, type="DNA")
</code></pre></div></div>

<p>Finally we need to attach the molecular sequence data to our model.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seq.clamp(seqData)
</code></pre></div></div>

<p>You may have wondered how the continuous trait model and the molecular
sequence model are combined. This happened automatically when you used
the same tree parameter <code class="language-plaintext highlighter-rouge">psi</code> for both models. Since both models share
now the same parameter, they will be used for a joint analyses. The
model function thus will construct the joint model graph for the
continuous trait model as well as the molecular sequence model.</p>

<p>After you ran the MCMC analyses, read in the tree trace. We will assume
that you used a tree monitor and called the file
<em>output/primates_joint.trees</em>. Change the name if you used a different
one.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>treetrace = readTreeTrace("output/primates_joint.trees", "clock")
</code></pre></div></div>

<p>Then build the maximum a posteriori tree.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>map = mapTree( file="primates_joint.tree", treetrace )
</code></pre></div></div>

<p>Write this model and make sure that it runs when you give it to
RevBayes.</p>

<h2 id="exercises-exercises-8-unnumbered">Exercises {#exercises-8 .unnumbered}</h2>

<ul>
  <li>
    <p>Run the analysis.</p>
  </li>
  <li>
    <p>Using <code class="language-plaintext highlighter-rouge">Tracer</code>, visualize the posterior distribution on the rate
parameter <code class="language-plaintext highlighter-rouge">sigma</code> and compare it to the previous analyses.</p>
  </li>
  <li>
    <p>Look at the MAP tree which you estimated now.</p>
  </li>
</ul>


<ol class="bibliography"><li><span id="Felsenstein1981">Felsenstein J. 1981. Evolutionary Trees from DNA Sequences: a Maximum Likelihood Approach. Journal of Molecular Evolution. 17:368–376.</span>

<a href="https://doi.org/10.1007/BF01734359">10.1007/BF01734359</a>

</li>
<li><span id="Felsenstein1985">Felsenstein J. 1985. Confidence limits on phylogenies: an approach using the bootstrap. Evolution. 39:783–791.</span>

<a href="https://doi.org/10.1111/j.1558-5646.1985.tb00420.x">10.1111/j.1558-5646.1985.tb00420.x</a>

</li>
<li><span id="Huelsenbeck2003">Huelsenbeck J.P., Rannala B. 2003. Detecting correlation between characters in a comparative analysis with uncertain phylogeny. Evolution. 57:1237–1247.</span>

<a href="https://doi.org/10.1111/j.0014-3820.2003.tb00332.x">10.1111/j.0014-3820.2003.tb00332.x</a>

</li></ol>

<script type="text/javascript">
var _ol = document.querySelectorAll('ol');
for (var i = 0, elem_ol; elem_ol = _ol[i]; i++) {
	if ( elem_ol.classList == "bibliography" ) {
		var _li = elem_ol.getElementsByTagName("li");
		//for (var j = 0, elem_li; elem_li = _li[j]; j++)
		//{
		//	elem_li.innerHTML = elem_li.innerHTML.replace(/(https?:\/\/)([^\s<]+)/,"<a href=\"$1$2\">$2");
		//}
		if(_li.length > 0)
			elem_ol.outerHTML = "<h2 class='references'>References</h2><hr class='references'>"+elem_ol.outerHTML
	}
}
</script>

      <br>
<footer>
  <div class="container">
  <div class="row">
    <div class="col-sm-12" align="center">
      <a href="https://github.com/revbayes">GitHub</a> | <a href="/license">License</a> | <a href="/citation">Citation</a> | <a href="https://groups.google.com/forum/#!forum/revbayes-users">Users Forum</a>
    </div>
  </div>
  <br>
  </div>
</footer>

    </div>
    <script src="/assets/js/vendor/jquery.min.js"></script>
<script src="/assets/js/vendor/FileSaver.min.js"></script>
<script src="/assets/js/vendor/jszip.min.js"></script>
<script src="/assets/js/vendor/bootstrap.min.js"></script>

<script type="text/javascript">
// Add default language
$(":not(code).highlighter-rouge").each(function() {
  
  if( this.classList == "highlighter-rouge") {
    this.classList = "Rev highlighter-rouge";
  }
  
});
// $("code.highlighter-rouge").each(function() {
//   
//   if( this.classList == "highlighter-rouge") {
//       this.classList = "Rev highlighter-rouge";
//   }
//   
// });
</script>
<script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
    });
    MathJax.Hub.Queue(function () {
      $(".aside").each(function() {
          $("div .MathJax", this).hide();
      });
    });
</script>
<script src="/assets/js/base.js"></script>

  </body>
</html>
